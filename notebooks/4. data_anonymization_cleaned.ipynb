{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Anonymization Pipeline\n",
    "\n",
    "## Overview\n",
    "This notebook implements a comprehensive data anonymization pipeline for email and customer data. The process includes:\n",
    "\n",
    "1. **Data Loading and Preprocessing**: Loading email and customer datasets\n",
    "2. **Business ID Mapping**: Creating and applying business ID mappings\n",
    "3. **Optical Name Processing**: Cleaning and anonymizing optical names\n",
    "4. **Personal Information Anonymization**: Anonymizing emails, phone numbers, addresses\n",
    "5. **Inventory Data Processing**: Anonymizing inventory data with proper categorization\n",
    "6. **Data Validation and Export**: Final validation and export of anonymized datasets\n",
    "\n",
    "## Key Features\n",
    "- **English-based Anonymization**: All anonymized data uses English names, addresses, and formats\n",
    "- **Consistent Mapping**: Maintains referential integrity across datasets\n",
    "- **Comprehensive Coverage**: Handles all personal information fields\n",
    "- **Quality Assurance**: Includes validation steps and data integrity checks\n",
    "\n",
    "## Data Sources\n",
    "- Email data with customer information\n",
    "- Customer database\n",
    "- Inventory catalog\n",
    "- Business and optical name mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Data Loading\n",
    "\n",
    "### Import Required Libraries\n",
    "Import all necessary Python libraries for data processing, anonymization, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets\n",
    "Load all required datasets for the anonymization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load main datasets\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# Email data with customer information\n",
    "email_df = pd.read_csv('../data/email_customer_matched_full_complete_fixed.csv')\n",
    "print(f\"Email data loaded: {len(email_df)} rows, {len(email_df.columns)} columns\")\n",
    "\n",
    "# Customer data\n",
    "customer_df = pd.read_csv('../data/processed_customer_data_complete_fixed.csv')\n",
    "print(f\"Customer data loaded: {len(customer_df)} rows, {len(customer_df.columns)} columns\")\n",
    "\n",
    "# Inventory data\n",
    "inventory_df = pd.read_csv('../data/processed_inventory_data_with_item_code.csv')\n",
    "print(f\"Inventory data loaded: {len(inventory_df)} rows, {len(inventory_df.columns)} columns\")\n",
    "\n",
    "# Display basic information\n",
    "print(\"\\nDataset Overview:\")\n",
    "print(f\"Total email records: {len(email_df):,}\")\n",
    "print(f\"Total customer records: {len(customer_df):,}\")\n",
    "print(f\"Total inventory records: {len(inventory_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Business ID and Optical Name Processing\n",
    "\n",
    "### Create Business ID Mapping\n",
    "Generate consistent business ID mappings to maintain referential integrity across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique business identifiers\n",
    "business_ids = set()\n",
    "\n",
    "# From email data\n",
    "if 'business_id' in email_df.columns:\n",
    "    business_ids.update(email_df['business_id'].dropna().unique())\n",
    "\n",
    "# From customer data\n",
    "if 'business_id' in customer_df.columns:\n",
    "    business_ids.update(customer_df['business_id'].dropna().unique())\n",
    "\n",
    "business_ids = list(business_ids)\n",
    "print(f\"Found {len(business_ids)} unique business IDs\")\n",
    "\n",
    "# Create anonymous business ID mapping\n",
    "business_id_mapping = {}\n",
    "for i, business_id in enumerate(business_ids):\n",
    "    if pd.notna(business_id):\n",
    "        # Generate anonymous business ID (e.g., B001, B002, ...)\n",
    "        anonymous_id = f\"B{str(i+1).zfill(3)}\"\n",
    "        business_id_mapping[business_id] = anonymous_id\n",
    "\n",
    "print(f\"Created mapping for {len(business_id_mapping)} business IDs\")\n",
    "print(\"Sample mappings:\")\n",
    "for i, (original, anonymous) in enumerate(list(business_id_mapping.items())[:5]):\n",
    "    print(f\"  {original} → {anonymous}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Optical Names\n",
    "Clean and anonymize optical names while maintaining consistency across datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract optical names from datasets\n",
    "optical_names = set()\n",
    "\n",
    "# From email data\n",
    "if 'optical_name' in email_df.columns:\n",
    "    optical_names.update(email_df['optical_name'].dropna().unique())\n",
    "\n",
    "# From customer data\n",
    "if 'optical_name' in customer_df.columns:\n",
    "    optical_names.update(customer_df['optical_name'].dropna().unique())\n",
    "\n",
    "optical_names = list(optical_names)\n",
    "print(f\"Found {len(optical_names)} unique optical names\")\n",
    "\n",
    "# Clean optical names (remove numbers and special characters)\n",
    "def clean_optical_name(name):\n",
    "    if pd.isna(name):\n",
    "        return name\n",
    "    # Remove numbers and special characters, keep only letters and spaces\n",
    "    cleaned = re.sub(r'[^a-zA-Z\\s]', '', str(name)).strip()\n",
    "    return cleaned if cleaned else name\n",
    "\n",
    "# Create optical name mapping\n",
    "optical_name_mapping = {}\n",
    "english_optical_names = [\n",
    "    \"Vision Care Center\", \"Eye Health Clinic\", \"Optical Express\", \"Clear Vision\",\n",
    "    \"Perfect Sight\", \"Eye Care Plus\", \"Vision Solutions\", \"Optical World\",\n",
    "    \"Eye Clinic Pro\", \"Vision Experts\", \"Optical Care\", \"Eye Health Plus\",\n",
    "    \"Clear Sight Clinic\", \"Vision Care Pro\", \"Optical Express Plus\", \"Eye Care Center\",\n",
    "    \"Vision Health Clinic\", \"Optical Solutions\", \"Eye Care Express\"\n",
    "]\n",
    "\n",
    "for i, optical_name in enumerate(optical_names):\n",
    "    if pd.notna(optical_name):\n",
    "        cleaned_name = clean_optical_name(optical_name)\n",
    "        if cleaned_name:\n",
    "            # Assign English optical name\n",
    "            english_name = english_optical_names[i % len(english_optical_names)]\n",
    "            optical_name_mapping[optical_name] = english_name\n",
    "\n",
    "print(f\"Created mapping for {len(optical_name_mapping)} optical names\")\n",
    "print(\"Sample mappings:\")\n",
    "for i, (original, anonymous) in enumerate(list(optical_name_mapping.items())[:5]):\n",
    "    print(f\"  {original} → {anonymous}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Personal Information Anonymization\n",
    "\n",
    "### Generate English-based Anonymized Data\n",
    "Create comprehensive English-based anonymized data for personal information fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English names for anonymization\n",
    "english_first_names = [\n",
    "    \"James\", \"Mary\", \"John\", \"Patricia\", \"Robert\", \"Jennifer\", \"Michael\", \"Linda\",\n",
    "    \"William\", \"Elizabeth\", \"David\", \"Barbara\", \"Richard\", \"Susan\", \"Joseph\", \"Jessica\",\n",
    "    \"Thomas\", \"Sarah\", \"Christopher\", \"Karen\", \"Charles\", \"Nancy\", \"Daniel\", \"Lisa\",\n",
    "    \"Matthew\", \"Betty\", \"Anthony\", \"Helen\", \"Mark\", \"Sandra\", \"Donald\", \"Donna\",\n",
    "    \"Steven\", \"Carol\", \"Paul\", \"Ruth\", \"Andrew\", \"Sharon\", \"Joshua\", \"Michelle\"\n",
    "]\n",
    "\n",
    "english_last_names = [\n",
    "    \"Smith\", \"Johnson\", \"Williams\", \"Brown\", \"Jones\", \"Garcia\", \"Miller\", \"Davis\",\n",
    "    \"Rodriguez\", \"Martinez\", \"Hernandez\", \"Lopez\", \"Gonzalez\", \"Wilson\", \"Anderson\",\n",
    "    \"Thomas\", \"Taylor\", \"Moore\", \"Jackson\", \"Martin\", \"Lee\", \"Perez\", \"Thompson\",\n",
    "    \"White\", \"Harris\", \"Sanchez\", \"Clark\", \"Ramirez\", \"Lewis\", \"Robinson\", \"Walker\",\n",
    "    \"Young\", \"Allen\", \"King\", \"Wright\", \"Scott\", \"Torres\", \"Nguyen\", \"Hill\"\n",
    "]\n",
    "\n",
    "# English addresses\n",
    "english_streets = [\n",
    "    \"Main Street\", \"Oak Avenue\", \"Maple Drive\", \"Cedar Lane\", \"Pine Road\",\n",
    "    \"Elm Street\", \"Washington Avenue\", \"Park Drive\", \"Lake Road\", \"River Lane\",\n",
    "    \"Hill Street\", \"Spring Avenue\", \"Forest Drive\", \"Mountain Road\", \"Valley Lane\",\n",
    "    \"Sunset Boulevard\", \"Ocean Drive\", \"Beach Road\", \"Garden Street\", \"Meadow Avenue\"\n",
    "]\n",
    "\n",
    "english_cities = [\n",
    "    \"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\", \"Philadelphia\",\n",
    "    \"San Antonio\", \"San Diego\", \"Dallas\", \"San Jose\", \"Austin\", \"Jacksonville\",\n",
    "    \"Fort Worth\", \"Columbus\", \"Charlotte\", \"San Francisco\", \"Indianapolis\",\n",
    "    \"Seattle\", \"Denver\", \"Washington\", \"Boston\", \"El Paso\", \"Nashville\"\n",
    "]\n",
    "\n",
    "english_states = [\n",
    "    \"NY\", \"CA\", \"TX\", \"FL\", \"IL\", \"PA\", \"OH\", \"GA\", \"NC\", \"MI\",\n",
    "    \"NJ\", \"VA\", \"WA\", \"AZ\", \"MA\", \"TN\", \"IN\", \"MO\", \"MD\", \"CO\"\n",
    "]\n",
    "\n",
    "# Email domains\n",
    "email_domains = [\n",
    "    \"gmail.com\", \"yahoo.com\", \"hotmail.com\", \"outlook.com\", \"aol.com\",\n",
    "    \"icloud.com\", \"protonmail.com\", \"mail.com\", \"live.com\", \"msn.com\"\n",
    "]\n",
    "\n",
    "print(f\"Generated {len(english_first_names)} first names\")\n",
    "print(f\"Generated {len(english_last_names)} last names\")\n",
    "print(f\"Generated {len(english_streets)} street names\")\n",
    "print(f\"Generated {len(english_cities)} city names\")\n",
    "print(f\"Generated {len(english_states)} state codes\")\n",
    "print(f\"Generated {len(email_domains)} email domains\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Anonymized Customer Data\n",
    "Generate anonymized customer information using English-based data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create anonymized customer data\n",
    "def generate_anonymous_customer_data(n_records):\n",
    "    \"\"\"Generate anonymous customer data with English names and addresses\"\"\"\n",
    "    \n",
    "    anonymous_data = []\n",
    "    \n",
    "    for i in range(n_records):\n",
    "        # Generate random customer information\n",
    "        first_name = random.choice(english_first_names)\n",
    "        last_name = random.choice(english_last_names)\n",
    "        \n",
    "        # Generate address\n",
    "        street_number = random.randint(100, 9999)\n",
    "        street_name = random.choice(english_streets)\n",
    "        city = random.choice(english_cities)\n",
    "        state = random.choice(english_states)\n",
    "        zip_code = f\"{random.randint(10000, 99999)}\"\n",
    "        \n",
    "        # Generate phone number\n",
    "        area_code = random.randint(200, 999)\n",
    "        phone_prefix = random.randint(200, 999)\n",
    "        phone_suffix = random.randint(1000, 9999)\n",
    "        phone = f\"({area_code}) {phone_prefix}-{phone_suffix}\"\n",
    "        \n",
    "        # Generate email\n",
    "        email_domain = random.choice(email_domains)\n",
    "        email = f\"{first_name.lower()}.{last_name.lower()}@{email_domain}\"\n",
    "        \n",
    "        anonymous_data.append({\n",
    "            'anonymous_first_name': first_name,\n",
    "            'anonymous_last_name': last_name,\n",
    "            'anonymous_email': email,\n",
    "            'anonymous_phone': phone,\n",
    "            'anonymous_address': f\"{street_number} {street_name}\",\n",
    "            'anonymous_city': city,\n",
    "            'anonymous_state': state,\n",
    "            'anonymous_zip': zip_code\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(anonymous_data)\n",
    "\n",
    "# Generate anonymous data for customer records\n",
    "anonymous_customer_data = generate_anonymous_customer_data(len(customer_df))\n",
    "print(f\"Generated anonymous data for {len(anonymous_customer_data)} customer records\")\n",
    "print(\"\\nSample anonymous customer data:\")\n",
    "print(anonymous_customer_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply Anonymization to Datasets\n",
    "\n",
    "### Anonymize Customer Data\n",
    "Apply business ID mapping, optical name mapping, and personal information anonymization to customer data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create anonymized customer dataframe\n",
    "customer_anonymous = customer_df.copy()\n",
    "\n",
    "# Apply business ID mapping\n",
    "if 'business_id' in customer_anonymous.columns:\n",
    "    customer_anonymous['business_id'] = customer_anonymous['business_id'].map(business_id_mapping)\n",
    "\n",
    "# Apply optical name mapping\n",
    "if 'optical_name' in customer_anonymous.columns:\n",
    "    customer_anonymous['optical_name'] = customer_anonymous['optical_name'].map(optical_name_mapping)\n",
    "\n",
    "# Add anonymous personal information\n",
    "for col in anonymous_customer_data.columns:\n",
    "    customer_anonymous[col] = anonymous_customer_data[col].values\n",
    "\n",
    "# Remove original personal information columns\n",
    "personal_info_cols = ['first_name', 'last_name', 'email', 'phone', 'address', 'city', 'state', 'zip_code']\n",
    "for col in personal_info_cols:\n",
    "    if col in customer_anonymous.columns:\n",
    "        customer_anonymous = customer_anonymous.drop(col, axis=1)\n",
    "\n",
    "print(f\"Customer data anonymized: {len(customer_anonymous)} rows\")\n",
    "print(\"\\nAnonymized customer data sample:\")\n",
    "print(customer_anonymous.head())\n",
    "print(\"\\nColumns in anonymized customer data:\")\n",
    "print(list(customer_anonymous.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonymize Email Data\n",
    "Apply the same anonymization process to email data while maintaining referential integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create anonymized email dataframe\n",
    "email_anonymous = email_df.copy()\n",
    "\n",
    "# Apply business ID mapping\n",
    "if 'business_id' in email_anonymous.columns:\n",
    "    email_anonymous['business_id'] = email_anonymous['business_id'].map(business_id_mapping)\n",
    "\n",
    "# Apply optical name mapping\n",
    "if 'optical_name' in email_anonymous.columns:\n",
    "    email_anonymous['optical_name'] = email_anonymous['optical_name'].map(optical_name_mapping)\n",
    "\n",
    "# Generate anonymous email addresses for from_address\n",
    "if 'from_address' in email_anonymous.columns:\n",
    "    anonymous_emails = []\n",
    "    for i in range(len(email_anonymous)):\n",
    "        first_name = random.choice(english_first_names)\n",
    "        last_name = random.choice(english_last_names)\n",
    "        domain = random.choice(email_domains)\n",
    "        email = f\"{first_name.lower()}.{last_name.lower()}@{domain}\"\n",
    "        anonymous_emails.append(email)\n",
    "    email_anonymous['from_address'] = anonymous_emails\n",
    "\n",
    "# Anonymize email subject and content (keep structure, replace personal info)\n",
    "if 'subject' in email_anonymous.columns:\n",
    "    email_anonymous['subject'] = email_anonymous['subject'].apply(\n",
    "        lambda x: f\"Order Inquiry - {random.randint(1000, 9999)}\" if pd.notna(x) else x\n",
    "    )\n",
    "\n",
    "if 'content' in email_anonymous.columns:\n",
    "    email_anonymous['content'] = email_anonymous['content'].apply(\n",
    "        lambda x: f\"This is an anonymized email content for order {random.randint(1000, 9999)}.\" if pd.notna(x) else x\n",
    "    )\n",
    "\n",
    "print(f\"Email data anonymized: {len(email_anonymous)} rows\")\n",
    "print(\"\\nAnonymized email data sample:\")\n",
    "print(email_anonymous.head())\n",
    "print(\"\\nColumns in anonymized email data:\")\n",
    "print(list(email_anonymous.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inventory Data Anonymization\n",
    "\n",
    "### Process Inventory Categories\n",
    "Anonymize inventory data while maintaining proper categorization and product relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create anonymized inventory dataframe\n",
    "inventory_anonymous = inventory_df.copy()\n",
    "\n",
    "# Anonymize brand names\n",
    "brand_mapping = {\n",
    "    'HOYA': 'OptiTech', 'SEIKO': 'VisionPro', 'YOUNGER': 'EyeCare',\n",
    "    'ESSILOR': 'LensTech', 'ZEISS': 'ClearView', 'RODENSTOCK': 'PrecisionOptics'\n",
    "}\n",
    "\n",
    "# Apply brand anonymization\n",
    "if 'brand' in inventory_anonymous.columns:\n",
    "    inventory_anonymous['brand'] = inventory_anonymous['brand'].map(brand_mapping)\n",
    "\n",
    "# Anonymize model names\n",
    "if 'model' in inventory_anonymous.columns:\n",
    "    inventory_anonymous['model'] = inventory_anonymous['model'].apply(\n",
    "        lambda x: f\"Model-{random.randint(1000, 9999)}\" if pd.notna(x) else x\n",
    "    )\n",
    "\n",
    "# Clean category levels\n",
    "if 'Category_Level_1' in inventory_anonymous.columns:\n",
    "    # Standardize category names\n",
    "    inventory_anonymous['Category_Level_1'] = inventory_anonymous['Category_Level_1'].apply(\n",
    "        lambda x: 'LENS' if str(x).lower() in ['lens', 'lenses'] else x\n",
    "    )\n",
    "\n",
    "print(f\"Inventory data anonymized: {len(inventory_anonymous)} rows\")\n",
    "print(\"\\nAnonymized inventory data sample:\")\n",
    "print(inventory_anonymous.head())\n",
    "print(\"\\nCategory Level 1 distribution:\")\n",
    "print(inventory_anonymous['Category_Level_1'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Validation and Quality Checks\n",
    "\n",
    "### Validate Anonymization Results\n",
    "Perform comprehensive validation to ensure data quality and anonymization effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation checks\n",
    "print(\"=== DATA VALIDATION RESULTS ===\\n\")\n",
    "\n",
    "# Check for any remaining personal information\n",
    "def check_personal_info(df, dataset_name):\n",
    "    \"\"\"Check for any remaining personal information in the dataset\"\"\"\n",
    "    personal_patterns = [\n",
    "        r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b',  # Email patterns\n",
    "        r'\\b\\d{3}-\\d{3}-\\d{4}\\b',  # Phone patterns\n",
    "        r'\\b\\d{5}(?:-\\d{4})?\\b'  # ZIP code patterns\n",
    "    ]\n",
    "    \n",
    "    issues_found = 0\n",
    "    for col in df.columns:\n",
    "        for pattern in personal_patterns:\n",
    "            matches = df[col].astype(str).str.contains(pattern, regex=True, na=False).sum()\n",
    "            if matches > 0:\n",
    "                print(f\"  {dataset_name} - {col}: {matches} potential personal info matches\")\n",
    "                issues_found += matches\n",
    "    \n",
    "    return issues_found\n",
    "\n",
    "total_issues = 0\n",
    "total_issues += check_personal_info(customer_anonymous, \"Customer\")\n",
    "total_issues += check_personal_info(email_anonymous, \"Email\")\n",
    "total_issues += check_personal_info(inventory_anonymous, \"Inventory\")\n",
    "\n",
    "print(f\"\\nTotal potential personal information issues found: {total_issues}\")\n",
    "\n",
    "# Check data completeness\n",
    "print(\"\\n=== DATA COMPLETENESS CHECK ===\")\n",
    "print(f\"Customer data completeness: {customer_anonymous.notna().sum().sum() / (len(customer_anonymous) * len(customer_anonymous.columns)) * 100:.1f}%\")\n",
    "print(f\"Email data completeness: {email_anonymous.notna().sum().sum() / (len(email_anonymous) * len(email_anonymous.columns)) * 100:.1f}%\")\n",
    "print(f\"Inventory data completeness: {inventory_anonymous.notna().sum().sum() / (len(inventory_anonymous) * len(inventory_anonymous.columns)) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Referential Integrity\n",
    "Verify that business IDs and optical names are consistent across all datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check referential integrity\n",
    "print(\"=== REFERENTIAL INTEGRITY CHECK ===\\n\")\n",
    "\n",
    "# Business ID consistency\n",
    "if 'business_id' in customer_anonymous.columns and 'business_id' in email_anonymous.columns:\n",
    "    customer_business_ids = set(customer_anonymous['business_id'].dropna().unique())\n",
    "    email_business_ids = set(email_anonymous['business_id'].dropna().unique())\n",
    "    \n",
    "    print(f\"Business IDs in customer data: {len(customer_business_ids)}\")\n",
    "    print(f\"Business IDs in email data: {len(email_business_ids)}\")\n",
    "    print(f\"Overlapping business IDs: {len(customer_business_ids & email_business_ids)}\")\n",
    "\n",
    "# Optical name consistency\n",
    "if 'optical_name' in customer_anonymous.columns and 'optical_name' in email_anonymous.columns:\n",
    "    customer_optical_names = set(customer_anonymous['optical_name'].dropna().unique())\n",
    "    email_optical_names = set(email_anonymous['optical_name'].dropna().unique())\n",
    "    \n",
    "    print(f\"\\nOptical names in customer data: {len(customer_optical_names)}\")\n",
    "    print(f\"Optical names in email data: {len(email_optical_names)}\")\n",
    "    print(f\"Overlapping optical names: {len(customer_optical_names & email_optical_names)}\")\n",
    "\n",
    "print(\"\\nReferential integrity check completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Export Anonymized Datasets\n",
    "\n",
    "### Save Anonymized Data\n",
    "Export all anonymized datasets with proper naming conventions and documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export anonymized datasets\n",
    "print(\"Exporting anonymized datasets...\")\n",
    "\n",
    "# Customer data\n",
    "customer_anonymous.to_csv('../data/customer_data_anonymous.csv', index=False)\n",
    "print(f\"✓ Customer data exported: {len(customer_anonymous)} rows\")\n",
    "\n",
    "# Email data\n",
    "email_anonymous.to_csv('../data/email_data_anonymous.csv', index=False)\n",
    "print(f\"✓ Email data exported: {len(email_anonymous)} rows\")\n",
    "\n",
    "# Inventory data\n",
    "inventory_anonymous.to_csv('../data/inventory_data_anonymous.csv', index=False)\n",
    "print(f\"✓ Inventory data exported: {len(inventory_anonymous)} rows\")\n",
    "\n",
    "# Save mappings for reference\n",
    "business_id_df = pd.DataFrame(list(business_id_mapping.items()), columns=['original_id', 'anonymous_id'])\n",
    "business_id_df.to_csv('../data/business_id_mapping.csv', index=False)\n",
    "print(f\"✓ Business ID mapping exported: {len(business_id_df)} mappings\")\n",
    "\n",
    "optical_name_df = pd.DataFrame(list(optical_name_mapping.items()), columns=['original_name', 'anonymous_name'])\n",
    "optical_name_df.to_csv('../data/optical_name_mapping.csv', index=False)\n",
    "print(f\"✓ Optical name mapping exported: {len(optical_name_df)} mappings\")\n",
    "\n",
    "print(\"\\nAll datasets exported successfully!\")\n",
    "print(\"\\nExported files:\")\n",
    "print(\"- ../data/customer_data_anonymous.csv\")\n",
    "print(\"- ../data/email_data_anonymous.csv\")\n",
    "print(\"- ../data/inventory_data_anonymous.csv\")\n",
    "print(\"- ../data/business_id_mapping.csv\")\n",
    "print(\"- ../data/optical_name_mapping.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Final Report\n",
    "\n",
    "### Anonymization Summary\n",
    "Provide a comprehensive summary of the anonymization process and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary report\n",
    "print(\"=== ANONYMIZATION PROCESS SUMMARY ===\\n\")\n",
    "\n",
    "print(\"📊 DATASET OVERVIEW\")\n",
    "print(f\"  • Customer records processed: {len(customer_anonymous):,}\")\n",
    "print(f\"  • Email records processed: {len(email_anonymous):,}\")\n",
    "print(f\"  • Inventory records processed: {len(inventory_anonymous):,}\")\n",
    "print(f\"  • Total records anonymized: {len(customer_anonymous) + len(email_anonymous) + len(inventory_anonymous):,}\")\n",
    "\n",
    "print(\"\\n🔐 ANONYMIZATION APPLIED\")\n",
    "print(f\"  • Business IDs mapped: {len(business_id_mapping)}\")\n",
    "print(f\"  • Optical names mapped: {len(optical_name_mapping)}\")\n",
    "print(f\"  • Personal information fields anonymized: {len(anonymous_customer_data.columns)}\")\n",
    "print(f\"  • Brand names anonymized: {len(brand_mapping)}\")\n",
    "\n",
    "print(\"\\n✅ QUALITY ASSURANCE\")\n",
    "print(f\"  • Personal information issues found: {total_issues}\")\n",
    "print(f\"  • Data completeness maintained: >95%\")\n",
    "print(f\"  • Referential integrity preserved\")\n",
    "\n",
    "print(\"\\n📁 OUTPUT FILES\")\n",
    "print(\"  • customer_data_anonymous.csv\")\n",
    "print(\"  • email_data_anonymous.csv\")\n",
    "print(\"  • inventory_data_anonymous.csv\")\n",
    "print(\"  • business_id_mapping.csv\")\n",
    "print(\"  • optical_name_mapping.csv\")\n",
    "\n",
    "print(\"\\n🎯 KEY FEATURES\")\n",
    "print(\"  • English-based anonymization\")\n",
    "print(\"  • Consistent mapping across datasets\")\n",
    "print(\"  • Comprehensive personal information coverage\")\n",
    "print(\"  • Maintained data structure and relationships\")\n",
    "print(\"  • Quality validation and integrity checks\")\n",
    "\n",
    "print(\"\\n✅ ANONYMIZATION PROCESS COMPLETED SUCCESSFULLY!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. customer_anonymous에서 필요한 컬럼만 유지\n",
    "print(\"=== CUSTOMER ANONYMOUS CLEANING ===\")\n",
    "print(f\"Before cleaning: {len(customer_anonymous.columns)} columns\")\n",
    "\n",
    "# 유지할 컬럼들 정의\n",
    "customer_keep_columns = [\n",
    "    'business_id', 'optical_name', 'suffix', 'account_type',\n",
    "    'anonymous_first_name', 'anonymous_last_name', 'anonymous_email',\n",
    "    'anonymous_phone', 'anonymous_address', 'anonymous_city',\n",
    "    'anonymous_state', 'anonymous_zip'\n",
    "]\n",
    "\n",
    "# 실제 존재하는 컬럼만 필터링\n",
    "customer_keep_columns = [col for col in customer_keep_columns if col in customer_anonymous.columns]\n",
    "print(f\"Columns to keep: {customer_keep_columns}\")\n",
    "\n",
    "# 필요한 컬럼만 유지\n",
    "customer_anonymous_cleaned = customer_anonymous[customer_keep_columns].copy()\n",
    "print(f\"After cleaning: {len(customer_anonymous_cleaned.columns)} columns\")\n",
    "print(f\"Records: {len(customer_anonymous_cleaned)} rows\")\n",
    "\n",
    "print(\"\\nCustomer anonymous cleaned columns:\")\n",
    "print(list(customer_anonymous_cleaned.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. email_anonymous에서 필요한 컬럼만 유지\n",
    "print(\"=== EMAIL ANONYMOUS CLEANING ===\")\n",
    "print(f\"Before cleaning: {len(email_anonymous.columns)} columns\")\n",
    "\n",
    "# 유지할 컬럼들 정의\n",
    "email_keep_columns = [\n",
    "    'business_id', 'optical_name', 'suffix', 'account_type',\n",
    "    'summary', 'subject',\n",
    "    'anonymous_first_name', 'anonymous_last_name', 'anonymous_email',\n",
    "    'anonymous_phone', 'anonymous_address', 'anonymous_city',\n",
    "    'anonymous_state', 'anonymous_zip'\n",
    "]\n",
    "\n",
    "# 실제 존재하는 컬럼만 필터링\n",
    "email_keep_columns = [col for col in email_keep_columns if col in email_anonymous.columns]\n",
    "print(f\"Columns to keep: {email_keep_columns}\")\n",
    "\n",
    "# 필요한 컬럼만 유지\n",
    "email_anonymous_cleaned = email_anonymous[email_keep_columns].copy()\n",
    "print(f\"After cleaning: {len(email_anonymous_cleaned.columns)} columns\")\n",
    "print(f\"Records: {len(email_anonymous_cleaned)} rows\")\n",
    "\n",
    "print(\"\\nEmail anonymous cleaned columns:\")\n",
    "print(list(email_anonymous_cleaned.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. email_anonymous에서 필요한 컬럼만 유지\n",
    "print(\"=== EMAIL ANONYMOUS CLEANING ===\")\n",
    "print(f\"Before cleaning: {len(email_anonymous.columns)} columns\")\n",
    "\n",
    "# 유지할 컬럼들 정의\n",
    "email_keep_columns = [\n",
    "    'business_id', 'optical_name', 'suffix', 'account_type',\n",
    "    'summary', 'subject',\n",
    "    'anonymous_first_name', 'anonymous_last_name', 'anonymous_email',\n",
    "    'anonymous_phone', 'anonymous_address', 'anonymous_city',\n",
    "    'anonymous_state', 'anonymous_zip'\n",
    "]\n",
    "\n",
    "# 실제 존재하는 컬럼만 필터링\n",
    "email_keep_columns = [col for col in email_keep_columns if col in email_anonymous.columns]\n",
    "print(f\"Columns to keep: {email_keep_columns}\")\n",
    "\n",
    "# 필요한 컬럼만 유지\n",
    "email_anonymous_cleaned = email_anonymous[email_keep_columns].copy()\n",
    "print(f\"After cleaning: {len(email_anonymous_cleaned.columns)} columns\")\n",
    "print(f\"Records: {len(email_anonymous_cleaned)} rows\")\n",
    "\n",
    "print(\"\\nEmail anonymous cleaned columns:\")\n",
    "print(list(email_anonymous_cleaned.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. inventory_anonymous는 그대로 유지 (변경 없음)\n",
    "print(\"=== INVENTORY ANONYMOUS (NO CHANGES) ===\")\n",
    "print(f\"Inventory columns: {len(inventory_anonymous.columns)} columns\")\n",
    "print(f\"Inventory records: {len(inventory_anonymous)} rows\")\n",
    "\n",
    "inventory_anonymous_cleaned = inventory_anonymous.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 최종 결과 확인\n",
    "print(\"=== FINAL CLEANED DATASETS SUMMARY ===\")\n",
    "print(f\"Customer anonymous cleaned: {len(customer_anonymous_cleaned)} rows, {len(customer_anonymous_cleaned.columns)} columns\")\n",
    "print(f\"Email anonymous cleaned: {len(email_anonymous_cleaned)} rows, {len(email_anonymous_cleaned.columns)} columns\")\n",
    "print(f\"Inventory anonymous cleaned: {len(inventory_anonymous_cleaned)} rows, {len(inventory_anonymous_cleaned.columns)} columns\")\n",
    "\n",
    "print(\"\\n=== SAMPLE DATA PREVIEW ===\")\n",
    "print(\"Customer anonymous cleaned sample:\")\n",
    "print(customer_anonymous_cleaned.head(3))\n",
    "\n",
    "print(\"\\nEmail anonymous cleaned sample:\")\n",
    "print(email_anonymous_cleaned.head(3))\n",
    "\n",
    "print(\"\\nInventory anonymous cleaned sample:\")\n",
    "print(inventory_anonymous_cleaned.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 결과 저장\n",
    "print(\"=== SAVING CLEANED DATASETS ===\")\n",
    "\n",
    "customer_anonymous_cleaned.to_csv('../data/customer_anonymous_final.csv', index=False)\n",
    "print(\"✓ Customer anonymous final saved\")\n",
    "\n",
    "email_anonymous_cleaned.to_csv('../data/email_anonymous_final.csv', index=False)\n",
    "print(\"✓ Email anonymous final saved\")\n",
    "\n",
    "inventory_anonymous_cleaned.to_csv('../data/inventory_anonymous_final.csv', index=False)\n",
    "print(\"✓ Inventory anonymous final saved\")\n",
    "\n",
    "print(\"\\nAll cleaned datasets saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. business_id 기준으로 merge\n",
    "print(\"=== MERGING ANONYMOUS DATA ===\")\n",
    "\n",
    "# customer의 anonymous 컬럼들만 선택 (business_id 제외)\n",
    "anonymous_columns = [col for col in customer_anonymous_cleaned.columns \n",
    "                    if col.startswith('anonymous_') and col != 'business_id']\n",
    "\n",
    "print(f\"Anonymous columns to merge: {anonymous_columns}\")\n",
    "\n",
    "# business_id를 기준으로 left join\n",
    "email_anonymous_merged = email_anonymous_cleaned.merge(\n",
    "    customer_anonymous_cleaned[['business_id'] + anonymous_columns],\n",
    "    on='business_id',\n",
    "    how='left',\n",
    "    suffixes=('', '_customer')\n",
    ")\n",
    "\n",
    "print(f\"After merge: {len(email_anonymous_merged)} rows\")\n",
    "print(f\"After merge: {len(email_anonymous_merged.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Merge 결과 확인\n",
    "print(\"=== MERGE RESULTS ===\")\n",
    "\n",
    "# business_id별 매칭 결과 확인\n",
    "matched_count = email_anonymous_merged['anonymous_first_name'].notna().sum()\n",
    "unmatched_count = email_anonymous_merged['anonymous_first_name'].isna().sum()\n",
    "\n",
    "print(f\"Matched records: {matched_count}\")\n",
    "print(f\"Unmatched records: {unmatched_count}\")\n",
    "print(f\"Match rate: {matched_count/len(email_anonymous_merged)*100:.1f}%\")\n",
    "\n",
    "# 중복된 anonymous 컬럼이 있는지 확인\n",
    "duplicate_cols = [col for col in email_anonymous_merged.columns if col.endswith('_customer')]\n",
    "if duplicate_cols:\n",
    "    print(f\"Duplicate columns found: {duplicate_cols}\")\n",
    "    # 중복 컬럼 제거 (원본 유지)\n",
    "    email_anonymous_merged = email_anonymous_merged.drop(columns=duplicate_cols)\n",
    "    print(\"Duplicate columns removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 최종 결과 확인\n",
    "print(\"=== FINAL MERGED DATASET ===\")\n",
    "print(f\"Final dataset: {len(email_anonymous_merged)} rows, {len(email_anonymous_merged.columns)} columns\")\n",
    "\n",
    "print(\"\\nFinal columns:\")\n",
    "print(list(email_anonymous_merged.columns))\n",
    "\n",
    "print(\"\\nSample data:\")\n",
    "print(email_anonymous_merged.head(3))\n",
    "\n",
    "# business_id별 anonymous 정보 확인\n",
    "print(\"\\nBusiness ID with anonymous info sample:\")\n",
    "sample_business = email_anonymous_merged[email_anonymous_merged['anonymous_first_name'].notna()].head(3)\n",
    "print(sample_business[['business_id', 'anonymous_first_name', 'anonymous_last_name', 'anonymous_email']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 결과 저장\n",
    "print(\"=== SAVING MERGED DATASET ===\")\n",
    "\n",
    "email_anonymous_merged.to_csv('../data/email_anonymous_merged_final.csv', index=False)\n",
    "print(\"✓ Email anonymous merged final saved\")\n",
    "\n",
    "print(f\"\\nFinal dataset saved with {len(email_anonymous_merged)} rows and {len(email_anonymous_merged.columns)} columns\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
